#!/bin/bash

echo "============================================================"
echo "STARTING SPARK DOCKER CLUSTER"
echo "============================================================"

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker first."
    exit 1
fi

# Stop any existing containers
echo "ğŸ›‘ Stopping any existing Spark containers..."
docker-compose down

# Start the cluster
echo "ğŸš€ Starting Spark cluster..."
docker-compose up -d

# Wait for containers to be ready
echo "â³ Waiting for containers to be ready..."
sleep 10

# Check container status
echo "ğŸ“Š Container status:"
docker-compose ps

# Check if containers are running
if docker-compose ps | grep -q "Up"; then
    echo "âœ… Spark cluster is running!"
    echo ""
    echo "ğŸŒ Access URLs:"
    echo "  - Spark Master UI: http://localhost:8080"
    echo "  - Spark Worker UI: http://localhost:8081"
    echo ""
    echo "ğŸ”§ To test cluster mode, run:"
    echo "  python -m pyspark_cluster.session_comparison"
    echo ""
    echo "ğŸ›‘ To stop the cluster:"
    echo "  docker-compose down"
else
    echo "âŒ Failed to start Spark cluster. Check the logs:"
    echo "  docker-compose logs"
fi 